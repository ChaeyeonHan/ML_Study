{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLStudy_01.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOxYQ54LJMx9OKIX4U5v+zU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChaeyeonHan/ML_Study/blob/main/MLStudy_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTQgRLETADON"
      },
      "source": [
        "## Linear Regression\n",
        "\n",
        "### Linear Regression(선형 회귀) VS Logisitic Regression(로지스틱 회귀)\n",
        "* 회귀(regression)란 ?  한바퀴 돌아 제자리로 돌아간다는 말로, 예를 들어 아버지의 키가 양 극단치로 갈수록 아들의 키는 인간의 평균적인 키로 되돌아가려는 성질을 이야기 할 수 있다. \n",
        "\n",
        "-> 데이터의 실측치와 모델의 실측치 사이의 차이가 평균으로 회귀하는 것이다. 정확한 모델에서는 잔차가 평균 0으로 회귀하게 된다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvdDDkfTCZSw"
      },
      "source": [
        "### Hypothesis and Cost Function\n",
        "가설과 비용함수\n",
        "hypothesis = W * x_data + b\n",
        "\n",
        "cost = tf.reduce_mean(tf.square(hypothesis- y_data)) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrFSYloc1iZb"
      },
      "source": [
        "hypothesis = W * x_data + b\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - y_data)) ## cost 함수"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqlLLjSW2YOK"
      },
      "source": [
        "# 평균 구하는 함수  : tf.reduce_mean()\n",
        "v = [1, 2, 3, 4]\n",
        "tf.reduce_mean(v)\n",
        "\n",
        "# tf.square()\n",
        "tf.square(3) # 9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGSFp3Uv3bGm"
      },
      "source": [
        "### Gradient descent : 경사하강 알고리즘\n",
        "cost 값을 최소화하는 것이 목표! \n",
        "minimization algorthim 중 하나 : Gradient descent(경사 하강 알고리즘)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7IZvq573aF6"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Data : 입력과 출력값을 동일하게 데이터 설정\n",
        "x_data = [1, 2, 3, 4, 5] \n",
        "y_data = [1, 2, 3, 4, 5]\n",
        "\n",
        "# W, b initaialize\n",
        "W = tf.Variable(2.9)\n",
        "b = tf.Variable(0.5)\n",
        "\n",
        "# learning_rate = 0.01\n",
        "\n",
        "for i in range(100) : # W, b update\n",
        "  # Gradient descent\n",
        "  with tf.GradientTape() as tape :\n",
        "    hypothesis = W * x_data + b;\n",
        "    cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n",
        "  W_grad, b_grad = tape.gradient(cost,[W, b])\n",
        "  #update parameter\n",
        "  W.assign_sub(learning_rate * W_grad)\n",
        "  b.assign_sub(learning_rate * b_grad)\n",
        "  if i % 10 == 0:\n",
        "    print(\"{:5}|{:10.4f}|{:10.6f}\".format(i, W.numpy(), b.numpy(), cost))\n",
        "  print()\n",
        "\n",
        "#predict 5와 2.5를 넣어서 값을 예측하기\n",
        "print(W * 5 + b)\n",
        "print(W * 2.5 + b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSc-F8rR85rl"
      },
      "source": [
        "GradientTape()은 with와 함께 사용되며 tape에 변수에 대한 정보를 저장한다.\n",
        "W_grad는 w의 기울기, b_grad는 b의 기울기(미분값)\n",
        "* A.assign_sub(B) : A = A - B, A -= B 와 동일한 의미\n",
        "\n",
        "learning_rate는 gradient 값을 얼마나 반영할지를 결정한다. \n",
        "\n",
        "-> 지속적으로 update해서 W(기울기)는 1에 가까워지고, b(y절편)는 0에 가까워진다. 두 개를 합쳐서 모델이 결정된다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJUV3iLWIrAz"
      },
      "source": [
        "## Computational Node 계산 그래프\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awh1_I1y3aNS",
        "outputId": "cc4dd71a-5bb1-40ce-b646-a14cef5f4827"
      },
      "source": [
        "# 노드 생성\n",
        "node1 = tf.constant(3.0, tf.float32)\n",
        "node2 = tf.constant(4.0)\n",
        "node3 = tf.add(node1, node2)\n",
        "\n",
        "print(\"node1:\", node1, \"node2:\",node2)\n",
        "print(\"node3:\", node3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "node1: tf.Tensor(3.0, shape=(), dtype=float32) node2: tf.Tensor(4.0, shape=(), dtype=float32)\n",
            "node3: tf.Tensor(7.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHBZz5AIJd3D"
      },
      "source": [
        "sess = tf.Session()\n",
        "print(\"sess.run(node1, node2): \", sess.run([node1, node2])\n",
        "\n",
        "print(\"sess.run(node3): \", sess.run(node3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJYZEh3LJ-di"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQI0mDkILFAi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7e9ec11-6099-4d07-a98c-c75a2aac7728"
      },
      "source": [
        "!git clone https://github.com/ChaeyeonHan/ML_Study.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ML_Study'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T47xNZsL6PD"
      },
      "source": [
        ""
      ]
    }
  ]
}
